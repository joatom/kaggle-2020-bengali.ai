{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image preprocessing\n",
    "The image preprocessing is based on these two notebooks https://www.kaggle.com/maxlenormand/cropping-to-character-resizing-images combined with https://www.kaggle.com/iafoss/image-preprocessing-128x128.\n",
    "\n",
    "The images are croped, scaled to fit the max image size and resized to 128x128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from fastai.vision import *\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slighty modified from https://www.kaggle.com/maxlenormand/cropping-to-character-resizing-images\n",
    "def crop_resize_scaled(df, resize_size = 128):\n",
    "    HEIGHT = 137\n",
    "    WIDTH = 236\n",
    "    CROP_SIZE = resize_size\n",
    "    original_img_size = HEIGHT * WIDTH\n",
    "    cropped_img_size = CROP_SIZE * CROP_SIZE\n",
    "    \n",
    "    print(f\"Original shape of images: {original_img_size}\\nCropped & resized shape of images: {cropped_img_size}\")\n",
    "    print(f\"Reduction fatio: {np.round(original_img_size/cropped_img_size, 3)}\")\n",
    "    print(df.shape)\n",
    "    resized_df = df.iloc[:, 1:].values.reshape(-1, HEIGHT, WIDTH)\n",
    "    \n",
    "    cropped_imgs = {}\n",
    "    for img_id in tqdm(range(df.shape[0])):\n",
    "        img = resized_df[img_id]\n",
    "        _, thresh = cv2.threshold(img, 30, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "        contours, _ = cv2.findContours(thresh,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)[-2:]\n",
    "        \n",
    "        idx = 0 \n",
    "        ls_xmin = []\n",
    "        ls_ymin = []\n",
    "        ls_xmax = []\n",
    "        ls_ymax = []\n",
    "        for cnt in contours:\n",
    "            idx += 1\n",
    "            x,y,w,h = cv2.boundingRect(cnt)\n",
    "            ls_xmin.append(x)\n",
    "            ls_ymin.append(y)\n",
    "            ls_xmax.append(x + w)\n",
    "            ls_ymax.append(y + h)\n",
    "        xmin = min(ls_xmin)\n",
    "        ymin = min(ls_ymin)\n",
    "        xmax = max(ls_xmax)\n",
    "        ymax = max(ls_ymax)\n",
    "\n",
    "        roi = img[ymin:ymax,xmin:xmax]\n",
    "        resized_roi = cv2.resize(roi, (resize_size, resize_size))\n",
    "        cropped_imgs[df.image_id[img_id]] = resized_roi.reshape(-1)\n",
    "        \n",
    "    resized = pd.DataFrame(cropped_imgs).T.reset_index()\n",
    "    resized.columns = resized.columns.astype(str)\n",
    "    resized.rename(columns={'index':'image_id'},inplace=True)\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def imagePreprocessing(crop_func, file_in, file_out):\n",
    "    df = pd.read_parquet(file_in)\n",
    "    df.reset_index(inplace=True,drop = True)#\n",
    "    print(df.shape)\n",
    "    cropped_df = crop_func(df, resize_size = 128)\n",
    "    cropped_df.to_feather(file_out)\n",
    "    del cropped_df\n",
    "    gc.collect()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kaggle/bengaliai-cv19/input/test_image_data_0.parquet /home/kaggle/bengaliai-cv19/input/test_image_data_crop_scaled_0.feather\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 296.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 32333)\n",
      "Original shape of images: 32332\n",
      "Cropped & resized shape of images: 16384\n",
      "Reduction fatio: 1.973\n",
      "(3, 32333)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Done\n",
      "/home/kaggle/bengaliai-cv19/input/test_image_data_1.parquet /home/kaggle/bengaliai-cv19/input/test_image_data_crop_scaled_1.feather\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 272.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 32333)\n",
      "Original shape of images: 32332\n",
      "Cropped & resized shape of images: 16384\n",
      "Reduction fatio: 1.973\n",
      "(3, 32333)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Done\n",
      "/home/kaggle/bengaliai-cv19/input/test_image_data_2.parquet /home/kaggle/bengaliai-cv19/input/test_image_data_crop_scaled_2.feather\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 391.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 32333)\n",
      "Original shape of images: 32332\n",
      "Cropped & resized shape of images: 16384\n",
      "Reduction fatio: 1.973\n",
      "(3, 32333)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Done\n",
      "/home/kaggle/bengaliai-cv19/input/test_image_data_3.parquet /home/kaggle/bengaliai-cv19/input/test_image_data_crop_scaled_3.feather\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 392.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 32333)\n",
      "Original shape of images: 32332\n",
      "Cropped & resized shape of images: 16384\n",
      "Reduction fatio: 1.973\n",
      "(3, 32333)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Done\n",
      "CPU times: user 7min 1s, sys: 3.31 s, total: 7min 4s\n",
      "Wall time: 1min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "source = Path('/home/kaggle/bengaliai-cv19/input')\n",
    "\n",
    "for i in range(4):\n",
    "    file_in = source/('test_image_data_' + str(i)+'.parquet')\n",
    "    file_out = source/('test_image_data_crop_scaled_' + str(i)+'.feather')\n",
    "    print(file_in, file_out)\n",
    "    imagePreprocessing(crop_resize_scaled,file_in, file_out)\n",
    "    print(str(i) + ' Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fastai]",
   "language": "python",
   "name": "conda-env-fastai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
